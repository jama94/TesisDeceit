{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"100Frames4FrameSpace50x50PorVideo4Conv.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"bBoXseK-M3qm","colab_type":"code","outputId":"5ed6a6f2-5087-43e6-dc39-49456b6fac00","colab":{"base_uri":"https://localhost:8080/","height":224}},"source":["!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticxxate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n","\n","\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["E: Package 'python-software-properties' has no installation candidate\n","Selecting previously unselected package google-drive-ocamlfuse.\n","(Reading database ... 131183 files and directories currently installed.)\n","Preparing to unpack .../google-drive-ocamlfuse_0.7.13-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n","Unpacking google-drive-ocamlfuse (0.7.13-0ubuntu1~ubuntu18.04.1) ...\n","Setting up google-drive-ocamlfuse (0.7.13-0ubuntu1~ubuntu18.04.1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","··········\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","Please enter the verification code: Access token retrieved correctly.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Sv5MmI0KYMs9","colab_type":"code","outputId":"149d5759-fa58-4e0a-df18-207204c68de1","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["!pip install -U tensorboardcolab\n","from tensorboardcolab import *\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already up-to-date: tensorboardcolab in /usr/local/lib/python3.6/dist-packages (0.0.22)\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"yTTwVBQyM3s1","colab_type":"code","colab":{}},"source":["!mkdir -p drive\n","!google-drive-ocamlfuse drive\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aZuhDZe1te-E","colab_type":"code","colab":{}},"source":["#tensorFlow para entrenar la red\n","import tensorflow as tf\n","\n","# numpy :D\n","import numpy as np\n","\n","# Imagenes\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils import shuffle\n","\n","#libreria números pseudo random\n","import random\n","random.seed(a=None)\n","\n","\n","# Graficado\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","%matplotlib inline\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kcmHmE4ePPXQ","colab_type":"code","colab":{}},"source":["path = 'drive/Colab Notebooks/'\n","save_file = path + 'checkpoint/train_model.ckpt'\n","data_file = path + 'Data'\n","sizeimage = 50\n","Frames = 100\n","filtros = 3"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-6dJkITAxR3g","colab_type":"text"},"source":["Cargar los datos de entrenamiento."]},{"cell_type":"code","metadata":{"id":"o1QOa_5A-g5g","colab_type":"code","colab":{}},"source":["dataTrainGS=np.load(data_file + str(Frames) + \"Cara/TrainGS\" + str(Frames) + \".npy\")\n","dataTrainSX=np.load(data_file + str(Frames) + \"Cara/TrainSX\" + str(Frames) + \".npy\")\n","dataTrainSY=np.load(data_file + str(Frames) + \"Cara/TrainSY\" + str(Frames) + \".npy\")\n","dataTrainKIR=np.load(data_file + str(Frames) + \"Cara/TrainKIR\" + str(Frames) + \".npy\")\n","dataTrainY=np.load(data_file + str(Frames) + \"Cara/TrainY\" + str(Frames) + \".npy\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"A8JOfkETAvAQ","colab_type":"code","outputId":"83ff3229-d955-4e2a-c12f-d453fcb66812","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["len(dataTrainY)\n","\n"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["643"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"Iw-uT2BjE6pl","colab_type":"text"},"source":["Este de abajo cambia dependiendo de que filtros este utilizando"]},{"cell_type":"code","metadata":{"id":"SjgBnZYcM35i","colab_type":"code","colab":{}},"source":["dataTrainGS,dataTrainSY,dataTrainSX,dataTrainKIR,dataTrainY = shuffle(dataTrainGS,dataTrainSY,dataTrainSX,dataTrainKIR,dataTrainY)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8_OaYte-u8hD","colab_type":"text"},"source":["Un pequeño porcentaje para la validación (aunque a estas alturas, se concluyó no daba ninguna información valiosa)"]},{"cell_type":"code","metadata":{"id":"rbpWPHsAy-av","colab_type":"code","colab":{}},"source":["\n","dataTrainGS = dataTrainGS[int(len(dataTrainGS)/20):]\n","dataTrainGS2 = dataTrainGS[:int(len(dataTrainGS)/20)]\n","dataTrainSY = dataTrainSY[int(len(dataTrainSY)/20):]\n","dataTrainSY2 = dataTrainSY[:int(len(dataTrainSY)/20)]\n","dataTrainSX = dataTrainSX[int(len(dataTrainSX)/20):]\n","dataTrainSX2 = dataTrainSX[:int(len(dataTrainSX)/20)]\n","dataTrainY = dataTrainY[int(len(dataTrainY)/20):]\n","dataTrainY2 = dataTrainY[:int(len(dataTrainY)/20)]\n","dataTrainKIR = dataTrainKIR[int(len(dataTrainKIR)/20):]\n","dataTrainKIR2 = dataTrainKIR[:int(len(dataTrainKIR)/20)]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-rNNs4UOvrJi","colab_type":"text"},"source":["Cargando los datos para hacer las pruebas y probar la robustez del modelo.\n","\n","Test es el conjunto de pruebas con personas nunca antes vistas.\n","\n","Test2 es el conjunto de pruebas con personas vistas.\n","\n","Se cargó por bloques para evitar que el GPU colapse."]},{"cell_type":"code","metadata":{"id":"S4T16--GSIVT","colab_type":"code","colab":{}},"source":["dataTestGS=np.load(data_file + str(Frames) + \"Cara/TestGS\" + str(Frames) + \".npy\",allow_pickle=True)\n","dataTestTruthGS2=np.load(data_file + str(Frames) + \"Cara/ValidationTruthGS\" + str(Frames) + \".npy\",allow_pickle=True)\n","dataTestDeceitGS2=np.load(data_file + str(Frames) + \"Cara/ValidationDeceitGS\" + str(Frames) + \".npy\",allow_pickle=True)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7snG-5zSSIYB","colab_type":"code","colab":{}},"source":["dataTestSX=np.load(data_file + str(Frames) + \"Cara/TestSX\" + str(Frames) + \".npy\",allow_pickle=True)\n","dataTestSY=np.load(data_file + str(Frames) + \"Cara/TestSY\" + str(Frames) + \".npy\",allow_pickle=True)\n","\n","dataTestTruthSX2=np.load(data_file + str(Frames) + \"Cara/ValidationTruthSX\" + str(Frames) + \".npy\",allow_pickle=True)\n","dataTestTruthSY2=np.load(data_file + str(Frames) + \"Cara/ValidationTruthSY\" + str(Frames) + \".npy\",allow_pickle=True)\n","\n","dataTestDeceitSX2=np.load(data_file + str(Frames) + \"Cara/ValidationDeceitSX\" + str(Frames) + \".npy\",allow_pickle=True)\n","dataTestDeceitSY2=np.load(data_file + str(Frames) + \"Cara/ValidationDeceitSY\" + str(Frames) + \".npy\",allow_pickle=True)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NM-MGCQvWetQ","colab_type":"code","colab":{}},"source":["\n","dataTestKIR=np.load(data_file + str(Frames) + \"Cara/TestKIR\" + str(Frames) + \".npy\",allow_pickle=True)\n","\n","dataTestTruthKIR2=np.load(data_file + str(Frames) + \"Cara/ValidationTruthKIR\" + str(Frames) + \".npy\",allow_pickle=True)\n","\n","dataTestDeceitKIR2=np.load(data_file + str(Frames) + \"Cara/ValidationDeceitKIR\" + str(Frames) + \".npy\",allow_pickle=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FVM-ukreGwa2","colab_type":"code","colab":{}},"source":["dataTestY=np.load(data_file + str(Frames) + \"Cara/TestY\" + str(Frames) + \".npy\",allow_pickle=True)\n","dataTestTruthY2=np.load(data_file + str(Frames) + \"Cara/ValidationTruthY\" + str(Frames) + \".npy\",allow_pickle=True)\n","dataTestDeceitY2=np.load(data_file + str(Frames) + \"Cara/ValidationDeceitY\" + str(Frames) + \".npy\",allow_pickle=True)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"I4B7n6F0te-x","colab_type":"code","colab":{}},"source":["x = tf.placeholder('float')\n","y = tf.placeholder('float')\n","n_classes = 2\n","batch_size = 10\n","keep_rate = 0.5\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"t8oxGJEKte-z","colab_type":"code","colab":{}},"source":["def conv3d(x, W):\n","    return tf.nn.conv3d(x, W, strides=[1,1,1,1,1], padding='VALID')\n","\n","def maxpool3d(x):\n","    #                        size of window         movement of window as you slide about\n","    return tf.nn.max_pool3d(x, ksize=[1,2,2,2,1], strides=[1,2,2,2,1], padding='SAME')\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"G_Rfz3BVOvDD","colab_type":"code","colab":{}},"source":["#Función para finalizar la sesión.\n","def reset_graph():\n","    if 'sess' in globals() and sess:\n","        sess.close()\n","    tf.reset_default_graph()\n","    \n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uvcv0_d9te-2","colab_type":"code","colab":{}},"source":["def convolutional_neural_network(\n","    keep_rate = 1,\n","    learn_rate= 1e-3,#antes erta 1618e-9\n","    n_classes=2,\n","    batch_size = 200\n","    ):\n","    reset_graph()\n","    \n","\n","    maxpool1 = [1,2,2,2,1]\n","    maxpool2 = [1,2,2,2,1]\n","    maxpool3 = [1,2,3,3,1]\n","    maxpool4 = [1,2,3,3,1]\n","    c1 = 4\n","    c2 = 8\n","    c3 = 16\n","    c4 = 32\n","    cf = 1*c4\n","    cf1 = 64\n","    cf2 = 64\n","    cf3 = 64\n","    cf4 = 64\n","    cf5 = 64\n","    cf6 = 64\n","    cf7 = 64\n","    cf8 = 64\n","    cf9 = 64\n","    \n","    xr   = tf.placeholder('float',[None,Frames,sizeimage,sizeimage])\n","    xg   = tf.placeholder('float',[None,Frames,sizeimage,sizeimage])\n","    xb   = tf.placeholder('float',[None,Frames,sizeimage,sizeimage])\n","    \n","    xgs   = tf.placeholder('float',[None,Frames,sizeimage,sizeimage])\n","    \n","    xsobx = tf.placeholder('float',[None,Frames,sizeimage,sizeimage])\n","    xsoby = tf.placeholder('float',[None,Frames,sizeimage,sizeimage])\n","\n","    xlap = tf.placeholder('float',[None,Frames,sizeimage,sizeimage])\n","    xkir = tf.placeholder('float',[None,Frames,sizeimage,sizeimage])\n","    \n","    xoptx = tf.placeholder('float',[None,Frames,sizeimage,sizeimage])\n","    xopty = tf.placeholder('float',[None,Frames,sizeimage,sizeimage])\n","    \n","    prob = tf.placeholder(tf.float32)\n","\n","    y = tf.placeholder('float')\n","    #n_classes = 2\n","    \n","\n","    #                # 9 imagenes x 3 x 3 kernel, 1 canal, 64 caracteristicas.\n","    weights = {'W_conv1':tf.Variable(tf.random_normal([9,3,3,1,c1])), \n","               #       7 imagenes x 8 x 8 kernel, 2 channels, 8 caracteristicas.\n","               'W_conv2':tf.Variable(tf.random_normal([7,3,3,c1,c2])),\n","               #       3imagenes x 8 x 8 kernel, 6 channels, 16 caracteristicas.\n","               'W_conv3':tf.Variable(tf.random_normal([7,3,3,c2,c3])),\n","               'W_conv4':tf.Variable(tf.random_normal([7,3,3,c3,c4])),#128\n","               'W_fc':tf.Variable(tf.random_normal([cf,cf])),#384\n","               'W_fc1':tf.Variable(tf.random_normal([cf,cf1])),\n","               'W_fc2':tf.Variable(tf.random_normal([cf1,cf2])),\n","               'W_fc3':tf.Variable(tf.random_normal([cf2,cf3])),\n","               'W_fc4':tf.Variable(tf.random_normal([cf3,cf4])),\n","               'W_fc5':tf.Variable(tf.random_normal([cf4,cf5])),\n","               'W_fc6':tf.Variable(tf.random_normal([cf5,cf6])),\n","               'W_fc7':tf.Variable(tf.random_normal([cf6,cf7])),\n","               'W_fc8':tf.Variable(tf.random_normal([cf7,cf8])),\n","               'W_fc9':tf.Variable(tf.random_normal([cf8,cf9])),\n","               'out':tf.Variable(tf.random_normal([cf9, n_classes]))}\n","\n","    biases = {'b_conv1':tf.Variable(tf.random_normal([c1])),\n","              'b_conv2':tf.Variable(tf.random_normal([c2])),\n","              'b_conv3':tf.Variable(tf.random_normal([c3])),\n","              'b_conv4':tf.Variable(tf.random_normal([c4])),\n","              'b_fc':tf.Variable(tf.random_normal([cf])),\n","              'b_fc1':tf.Variable(tf.random_normal([cf1])),\n","              'b_fc2':tf.Variable(tf.random_normal([cf2])),\n","              'b_fc3':tf.Variable(tf.random_normal([cf3])),\n","              'b_fc4':tf.Variable(tf.random_normal([cf4])),\n","              'b_fc5':tf.Variable(tf.random_normal([cf5])),\n","              'b_fc6':tf.Variable(tf.random_normal([cf6])),\n","              'b_fc7':tf.Variable(tf.random_normal([cf7])),\n","              'b_fc8':tf.Variable(tf.random_normal([cf8])),\n","              'b_fc9':tf.Variable(tf.random_normal([cf9])),\n","              'out':tf.Variable(tf.random_normal([n_classes]))}\n","\n","    #                             image z   image Y   image x\n","    xr1   = tf.reshape(xr,   shape=[-1,      Frames,      sizeimage,      sizeimage,      1])\n","    xg1   = tf.reshape(xg,   shape=[-1,      Frames,      sizeimage,      sizeimage,      1])\n","    xb1   = tf.reshape(xb,   shape=[-1,      Frames,      sizeimage,      sizeimage,      1])\n","    \n","    xgs1   = tf.reshape(xgs,   shape=[-1,      Frames,      sizeimage,      sizeimage,      1])\n","    \n","    xsobx1 = tf.reshape(xsobx, shape=[-1,      Frames,      sizeimage,      sizeimage,      1])\n","    xsoby1 = tf.reshape(xsoby, shape=[-1,      Frames,      sizeimage,      sizeimage,      1])\n","    \n","    xlap1 = tf.reshape(xlap, shape=[-1,      Frames,      sizeimage,      sizeimage,      1])\n","    xkir1 = tf.reshape(xkir, shape=[-1,      Frames,      sizeimage,      sizeimage,      1])\n","    \n","    xoptx1 = tf.reshape(xoptx, shape=[-1,      Frames,      sizeimage,      sizeimage,      1])\n","    xopty1 = tf.reshape(xopty, shape=[-1,      Frames,      sizeimage,      sizeimage,      1])\n","\n","    print(\"filtro\")\n","    conv1gs = tf.nn.relu(conv3d(xgs1, weights['W_conv1']) + biases['b_conv1'])\n","    print(conv1gs)\n","    conv1gs = tf.nn.max_pool3d(conv1gs, ksize=maxpool1, strides=maxpool1, padding='SAME')\n","    print(conv1gs)\n","    conv2gs = tf.nn.relu(conv3d(conv1gs, weights['W_conv2']) + biases['b_conv2'])\n","    print(conv2gs)\n","    conv2gs = tf.nn.max_pool3d(conv2gs, ksize=maxpool2, strides=maxpool2, padding='SAME')\n","    print(conv2gs)\n","    conv3gs = tf.nn.relu(conv3d(conv2gs, weights['W_conv3']) + biases['b_conv3'])\n","    print(conv3gs)\n","    conv3gs = tf.nn.max_pool3d(conv3gs, ksize=maxpool3, strides=maxpool3, padding='VALID')\n","    print(conv3gs)\n","    conv4gs = tf.nn.relu(conv3d(conv3gs, weights['W_conv4']) + biases['b_conv4'])\n","    print(conv4gs)\n","    \n","    print(\"filtro\")\n","    conv1sobx = tf.nn.relu(conv3d(xsobx1, weights['W_conv1']) + biases['b_conv1'])\n","    print(conv1sobx)\n","    conv1sobx = tf.nn.max_pool3d(conv1sobx, ksize=maxpool1, strides=maxpool1, padding='SAME')\n","    print(conv1sobx)\n","    conv2sobx = tf.nn.relu(conv3d(conv1sobx, weights['W_conv2']) + biases['b_conv2'])\n","    print(conv2sobx)\n","    conv2sobx = tf.nn.max_pool3d(conv2sobx, ksize=maxpool2, strides=maxpool2, padding='SAME')\n","    print(conv2sobx)\n","    conv3sobx = tf.nn.relu(conv3d(conv2sobx, weights['W_conv3']) + biases['b_conv3'])\n","    print(conv3sobx)\n","    conv3sobx = tf.nn.max_pool3d(conv3sobx, ksize=maxpool3, strides=maxpool3, padding='VALID')\n","    print(conv3sobx)\n","    conv4sobx = tf.nn.relu(conv3d(conv3sobx, weights['W_conv4']) + biases['b_conv4'])\n","    print(conv4sobx)\n","\n","    print(\"filtro\")\n","    conv1soby = tf.nn.relu(conv3d(xsoby1, weights['W_conv1']) + biases['b_conv1'])\n","    print(conv1soby)\n","    conv1soby = tf.nn.max_pool3d(conv1soby, ksize=maxpool1, strides=maxpool1, padding='SAME')\n","    print(conv1soby)\n","    conv2soby = tf.nn.relu(conv3d(conv1soby, weights['W_conv2']) + biases['b_conv2'])\n","    print(conv2soby)\n","    conv2soby = tf.nn.max_pool3d(conv2soby, ksize=maxpool2, strides=maxpool2, padding='SAME')\n","    print(conv2soby)\n","    conv3soby = tf.nn.relu(conv3d(conv2soby, weights['W_conv3']) + biases['b_conv3'])\n","    print(conv3soby)\n","    conv3soby = tf.nn.max_pool3d(conv3soby, ksize=maxpool3, strides=maxpool3, padding='VALID')\n","    print(conv3soby)\n","    conv4soby = tf.nn.relu(conv3d(conv3soby, weights['W_conv4']) + biases['b_conv4'])\n","    print(conv4soby)\n","    \n","    print(\"concatenacion\")\n","    conv = tf.concat([conv4gs, conv4sobx, conv4soby], -1)\n","    #conv = tf.multiply(conv4gs, conv4kir)\n","    #conv2 = tf.multiply(conv4sobx, conv4soby)\n","    #conv = tf.multiply(conv, conv4soby)\n","    print(conv)\n","    \n","    fc = tf.reshape(conv,[-1, cf])\n","    fc = tf.nn.tanh(tf.matmul(fc, weights['W_fc'])+biases['b_fc'])\n","    fc = tf.nn.dropout(fc, rate=1-prob)\n","    print(fc)\n","    \n","    fc1 = tf.nn.relu(tf.matmul(fc, weights['W_fc1'])+biases['b_fc1'])\n","    fc1 = tf.nn.dropout(fc1, rate=1-prob)\n","    print(fc1)\n","    \n","    fc2 = tf.nn.relu(tf.matmul(fc1, weights['W_fc2'])+biases['b_fc2'])\n","    fc2 = tf.nn.dropout(fc2, rate=1-prob)\n","    print(fc2)\n","    \n","    fc3 = tf.nn.relu(tf.matmul(fc2, weights['W_fc3'])+biases['b_fc3'])\n","    fc3 = tf.nn.dropout(fc3, rate=1-prob)\n","    print(fc3)\n","    \n","    fc4 = tf.nn.relu(tf.matmul(fc3, weights['W_fc4'])+biases['b_fc4'])\n","    fc4 = tf.nn.dropout(fc4, rate=1-prob)\n","    print(fc4)\n","    \n","    fc5 = tf.nn.relu(tf.matmul(fc4, weights['W_fc5'])+biases['b_fc5'])\n","    fc5 = tf.nn.dropout(fc5, rate=1-prob)\n","    print(fc5)\n","    \n","    fc6 = tf.nn.relu(tf.matmul(fc5, weights['W_fc6'])+biases['b_fc6'])\n","    fc6 = tf.nn.dropout(fc6, rate=1-prob)\n","    print(fc6)\n","    \n","    fc7 = tf.nn.relu(tf.matmul(fc6, weights['W_fc7'])+biases['b_fc7'])\n","    fc7 = tf.nn.dropout(fc7, rate=1-prob)\n","    print(fc7)\n","    \n","    fc8 = tf.nn.relu(tf.matmul(fc7, weights['W_fc8'])+biases['b_fc8'])\n","    fc8 = tf.nn.dropout(fc8, rate=1-prob)\n","    print(fc8)\n","    \n","    fc9 = tf.nn.relu(tf.matmul(fc8, weights['W_fc9'])+biases['b_fc9'])\n","    fc9 = tf.nn.dropout(fc9, rate=0)\n","    print(fc9)\n","    \n","    output = tf.matmul(fc9, weights['out'])+biases['out']\n","    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=output))\n","    optimizer = tf.train.AdamOptimizer(learn_rate).minimize(cost)\n","    \n","    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(output,1))\n","    accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n","    \n","    return dict(\n","              x=x,\n","              xr = xr,\n","              xg = xg,\n","              xb = xb,\n","              xgs = xgs,\n","              xsobx = xsobx,\n","              xsoby = xsoby,\n","              xlap = xlap,\n","              xkir = xkir,\n","              xoptx = xoptx,\n","              xopty = xopty,\n","              y=y,\n","              prob = prob,\n","              output=output,\n","              cost=cost,\n","              optimizer=optimizer,\n","              accuracy = accuracy\n","              )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qd6A4pO0ZTz0","colab_type":"code","outputId":"0b37f129-d71e-4a6c-80cd-cae0029eea38","colab":{"base_uri":"https://localhost:8080/","height":765}},"source":["DNN=convolutional_neural_network(keep_rate = 0.5)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["filtro\n","Tensor(\"Relu:0\", shape=(?, 92, 48, 48, 6), dtype=float32)\n","Tensor(\"MaxPool3D:0\", shape=(?, 46, 24, 24, 6), dtype=float32)\n","Tensor(\"Relu_1:0\", shape=(?, 40, 22, 22, 16), dtype=float32)\n","Tensor(\"MaxPool3D_1:0\", shape=(?, 20, 11, 11, 16), dtype=float32)\n","Tensor(\"Relu_2:0\", shape=(?, 14, 9, 9, 32), dtype=float32)\n","Tensor(\"MaxPool3D_2:0\", shape=(?, 7, 3, 3, 32), dtype=float32)\n","Tensor(\"Relu_3:0\", shape=(?, 1, 1, 1, 128), dtype=float32)\n","filtro\n","Tensor(\"Relu_4:0\", shape=(?, 92, 48, 48, 6), dtype=float32)\n","Tensor(\"MaxPool3D_3:0\", shape=(?, 46, 24, 24, 6), dtype=float32)\n","Tensor(\"Relu_5:0\", shape=(?, 40, 22, 22, 16), dtype=float32)\n","Tensor(\"MaxPool3D_4:0\", shape=(?, 20, 11, 11, 16), dtype=float32)\n","Tensor(\"Relu_6:0\", shape=(?, 14, 9, 9, 32), dtype=float32)\n","Tensor(\"MaxPool3D_5:0\", shape=(?, 7, 3, 3, 32), dtype=float32)\n","Tensor(\"Relu_7:0\", shape=(?, 1, 1, 1, 128), dtype=float32)\n","filtro\n","Tensor(\"Relu_8:0\", shape=(?, 92, 48, 48, 6), dtype=float32)\n","Tensor(\"MaxPool3D_6:0\", shape=(?, 46, 24, 24, 6), dtype=float32)\n","Tensor(\"Relu_9:0\", shape=(?, 40, 22, 22, 16), dtype=float32)\n","Tensor(\"MaxPool3D_7:0\", shape=(?, 20, 11, 11, 16), dtype=float32)\n","Tensor(\"Relu_10:0\", shape=(?, 14, 9, 9, 32), dtype=float32)\n","Tensor(\"MaxPool3D_8:0\", shape=(?, 7, 3, 3, 32), dtype=float32)\n","Tensor(\"Relu_11:0\", shape=(?, 1, 1, 1, 128), dtype=float32)\n","filtro\n","Tensor(\"Relu_12:0\", shape=(?, 92, 48, 48, 6), dtype=float32)\n","Tensor(\"MaxPool3D_9:0\", shape=(?, 46, 24, 24, 6), dtype=float32)\n","Tensor(\"Relu_13:0\", shape=(?, 40, 22, 22, 16), dtype=float32)\n","Tensor(\"MaxPool3D_10:0\", shape=(?, 20, 11, 11, 16), dtype=float32)\n","Tensor(\"Relu_14:0\", shape=(?, 14, 9, 9, 32), dtype=float32)\n","Tensor(\"MaxPool3D_11:0\", shape=(?, 7, 3, 3, 32), dtype=float32)\n","Tensor(\"Relu_15:0\", shape=(?, 1, 1, 1, 128), dtype=float32)\n","concatenacion\n","Tensor(\"Mul:0\", shape=(?, 1, 1, 1, 128), dtype=float32)\n","Tensor(\"dropout/mul_1:0\", shape=(?, 128), dtype=float32)\n","Tensor(\"dropout_1/mul_1:0\", shape=(?, 128), dtype=float32)\n","Tensor(\"dropout_2/mul_1:0\", shape=(?, 128), dtype=float32)\n","Tensor(\"dropout_3/mul_1:0\", shape=(?, 128), dtype=float32)\n","Tensor(\"dropout_4/mul_1:0\", shape=(?, 128), dtype=float32)\n","Tensor(\"dropout_5/mul_1:0\", shape=(?, 128), dtype=float32)\n","Tensor(\"dropout_6/mul_1:0\", shape=(?, 128), dtype=float32)\n","Tensor(\"dropout_7/mul_1:0\", shape=(?, 128), dtype=float32)\n","Tensor(\"dropout_8/mul_1:0\", shape=(?, 64), dtype=float32)\n","Tensor(\"Relu_24:0\", shape=(?, 64), dtype=float32)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pHCU8Gt8RsrK","colab_type":"code","colab":{}},"source":["def train_neural_network(DNN, hm_epochs = 10,batch_size=70):\n","    saver = tf.train.Saver()\n","    \n","    with tf.Session() as sess:\n","        #saver.restore(sess,save_file)\n","        sess.run(tf.global_variables_initializer())\n","  \n","        DV = 1\n","        bestWeights = 0\n","         ########################################################################## training\n","        \n","        for epoch in range(hm_epochs):        \n","          \n","            epoch_loss = 0\n","            epoch_lossVal = 0\n","            i=0\n","            acctrain = 0\n","            contador = 0\n","            while i < len(dataTrainY)/batch_size:\n","                start = i\n","                end = i+batch_size\n","\n","                feed_dict={DNN[\"xgs\"]:   dataTrainGS[start:end],\n","                           DNN[\"xsobx\"]: dataTrainSX[start:end],\n","                           DNN[\"xsoby\"]: dataTrainSY[start:end],\n","                           DNN[\"y\"]:    dataTrainY[start:end],\n","                           DNN[\"prob\"]: DV} #antes era 45\n","                _, c, accuracy  = sess.run([DNN[\"optimizer\"], DNN[\"cost\"]    # _, c, output\n","                                                 , DNN[\"accuracy\"]], #DNN[\"output\"]\n","                                                feed_dict=feed_dict)\n","                acctrain = acctrain + accuracy\n","                \n","                epoch_loss += c\n","                \n","                contador = contador + 1\n","                i+=batch_size \n","            \n","             ########################################################################## Validation\n","            \n","            \n","            \n","            feed_dict={DNN[\"xgs\"]:   dataTrainGS2,\n","                       DNN[\"xsobx\"]: dataTrainSX2,\n","                       DNN[\"xsoby\"]: dataTrainSY2,\n","                       DNN[\"y\"]:     dataTrainY2,\n","                       DNN[\"prob\"]: 1} #antes era 45\n","            \n","            accuracyVal,cVal  = sess.run([DNN[\"accuracy\"],DNN[\"cost\"]],feed_dict=feed_dict)\n","            epoch_lossVal += cVal\n","                \n","            #print('\\n\\nEpoch', epoch, 'completed out of',hm_epochs)\n","            #print('LossTraining:\\t',epoch_loss,'lossValidation:\\t',epoch_lossVal)\n","            #print('Train: \\t  accuracyValidation:\\t',accuracyVal, '\\t accuracyTraining:\\t',acctrain/contador)\n","            \n","            if((acctrain/contador) > 0.6 and (acctrain/contador) < 0.8):\n","              DV = 0.9\n","            elif((acctrain/contador) > 0.8):\n","              DV = 0.8\n","            else:\n","              DV = 1\n","            \n","            ########################################################################## impresion tensorboard training validation\n","            \n","            \n","            tbc.save_value(\"LossTrain\", \"lossTrain\", epoch, epoch_loss)\n","            tbc.save_value(\"AccuracyTrain\", \"accuracyTrain\", epoch, acctrain/contador)\n","            \n","            tbc.save_value(\"LossTrain\", \"lossValidation\", epoch, epoch_lossVal)\n","            tbc.save_value(\"AccuracyTrain\", \"accuracyValidation\", epoch, accuracyVal)\n","            \n","            tbc.flush_line(\"lossTrain\")\n","            tbc.flush_line(\"accuracyTrain\")\n","            tbc.flush_line(\"lossValidation\")\n","            tbc.flush_line(\"accuracyValidation\")\n","     \n","            ########################################################################## test uno (personas que nunca se vieron)\n","            \n","            if((epoch+1)%1 == 0):\n","              \n","                ta1 = 0 #variable de impresion\n","                ta11 = 0  #variable de impresion\n","                \n","                \n","                acctest1 = 0\n","                \n","                accumaccuracy = 0\n","                epoch_lossTest = 0\n","                contadorTotal = 0\n","                contadorTotalcorrecto = 0\n","                \n","                contadorVerdadPositiva = 0\n","                contadorVerdadNegativa = 0\n","                contadorMentiraPositiva = 0\n","                contadorMentiraNegativa = 0\n","                for x in range(len(dataTestY)):\n","                  if(len(dataTestGS[x]) != 0 ):\n","                    feed_dict={DNN[\"xgs\"]:   dataTestGS[x],\n","                               DNN[\"xsobx\"]: dataTestSX[x],\n","                               DNN[\"xsoby\"]: dataTestSY[x],\n","                               DNN[\"y\"]:     dataTestY[x],\n","                               DNN[\"prob\"]: 1} #antes era 45\n","                    predictionTest,yTest,accuracyTest,cTest   = sess.run([DNN[\"output\"], DNN[\"y\"], DNN[\"accuracy\"],DNN[\"cost\"]],\n","                                                                         feed_dict=feed_dict)\n","                    \n","                    epoch_lossTest += cTest\n","                    \n","                    \n","                    \n","                    contadorCorrecto = 0\n","                    contadorIncorrecto = 0\n","                    \n","                    for i in range(len(dataTestY[x])):\n","                        if((predictionTest[i][0]>predictionTest[i][1] and yTest[i][0]>yTest[i][1]) or\n","                           (predictionTest[i][0]<predictionTest[i][1] and yTest[i][0]<yTest[i][1])):\n","                          \n","                          contadorCorrecto = contadorCorrecto + 1\n","                          \n","                          if(x > 20):\n","                            \n","                            if((x+1) % 2 == 0):\n","                              contadorMentiraPositiva += 1\n","                            else:\n","                              contadorMentiraNegativa += 1\n","                              \n","                          else:\n","                            \n","                            if((x+1) % 2 == 0):\n","                              contadorVerdadPositiva += 1\n","                            else:\n","                              contadorVerdadNegativa += 1\n","                              \n","                        else:\n","                          contadorIncorrecto = contadorIncorrecto + 1\n","                          \n","                        \n","                        \n","                    if(contadorCorrecto >  contadorIncorrecto):\n","                      accumaccuracy = accumaccuracy + 1\n","                    contadorTotal = contadorTotal + contadorCorrecto + contadorIncorrecto\n","                    contadorTotalcorrecto = contadorTotalcorrecto + contadorCorrecto\n","                    \n","                acctest1 = contadorTotalcorrecto/contadorTotal\n","                \n","                #print('Test1: \\t epoch_lossTest1 \\t',epoch_lossTest)\n","                #print('Test1: \\t accuracyPorVideoTest1 \\t',accumaccuracy/len(dataTestY),'\\t accuracyGlobal \\t',acctest1)\n","                #print('Test1: \\t contadorMentiraPositiva \\t',(contadorMentiraPositiva/contadorTotal)/acctest1,'\\t contadorMentiraNegativa \\t',(contadorMentiraNegativa/contadorTotal)/acctest1)\n","                #print('Test1: \\t contadorVerdadPositiva \\t',(contadorVerdadPositiva/contadorTotal)/acctest1,'\\t contadorVerdadNegativa \\t',(contadorVerdadNegativa/contadorTotal)/acctest1)\n","                \n","                \n","                \n","                \n","                ########################################################################## impresion tensorboard test1\n","                tbc.save_value(\"AccuracyTest\", \"accuracyGlobal1\", epoch, acctest1)\n","                tbc.flush_line(\"accuracyGlobal1\")\n","                \n","                tbc.save_value(\"LossTest\", \"lossTest\", epoch, epoch_lossTest)\n","                tbc.save_value(\"AccuracyTest\", \"accuracyPorVideo1\", epoch, accumaccuracy/len(dataTestY))\n","                tbc.flush_line(\"lossTest\")\n","                \n","                ######################################################################### Test dos (personas ya vistas) verdad\n","                \n","                \n","                ta2 = 0  #variable de impresion\n","                ta22 = 0  #variable de impresion\n","                \n","                \n","                acctest2 = 0   \n","                   \n","                accumaccuracy = 0\n","                epoch_lossTest = 0\n","                contadorTotal = 0\n","                contadorTotalcorrecto = 0\n","                   \n","                   \n","                contadorVerdadNegativa = 0\n","                contadorMentiraPositiva = 0\n","                   \n","                acctotal = 0\n","                   \n","                for x in range(len(dataTestTruthY2)+len(dataTestDeceitY2)):\n","                  if((x+1) < len(dataTestTruthY2)):\n","                    feed_dict={DNN[\"xgs\"]:   dataTestTruthGS2[x],\n","                               DNN[\"xsobx\"]: dataTestTruthSX2[x],\n","                               DNN[\"xsoby\"]: dataTestTruthSY2[x],\n","                               DNN[\"y\"]:     dataTestTruthY2[x],\n","                               DNN[\"prob\"]: 1} \n","                    predictionTest,yTest,accuracyTest,cTest   = sess.run([DNN[\"output\"], DNN[\"y\"], DNN[\"accuracy\"],DNN[\"cost\"]],\n","                                                                         feed_dict=feed_dict)\n","                    epoch_lossTest += cTest\n","                    \n","                    contadorCorrecto = 0\n","                    contadorIncorrecto = 0\n","                   \n","                    for i in range(len(dataTestTruthY2[x])):\n","                        if((predictionTest[i][0]>predictionTest[i][1] and yTest[i][0]>yTest[i][1]) or\n","                           (predictionTest[i][0]<predictionTest[i][1] and yTest[i][0]<yTest[i][1])):\n","                          contadorCorrecto = contadorCorrecto + 1\n","                        else:\n","                          contadorIncorrecto = contadorIncorrecto + 1\n","                    if(contadorCorrecto >  contadorIncorrecto):\n","                      accumaccuracy = accumaccuracy + 1\n","                      contadorVerdadNegativa += 1\n","                   \n","                    contadorTotal = contadorTotal + contadorCorrecto + contadorIncorrecto\n","                    contadorTotalcorrecto = contadorTotalcorrecto + contadorCorrecto\n","                    \n","                  else:\n","                    feed_dict={DNN[\"xgs\"]:   dataTestDeceitGS2[x-len(dataTestTruthY2)],\n","                               DNN[\"xsobx\"]: dataTestDeceitSX2[x-len(dataTestTruthY2)],\n","                               DNN[\"xsoby\"]: dataTestDeceitSY2[x-len(dataTestTruthY2)],\n","                               DNN[\"y\"]:     dataTestDeceitY2[x-len(dataTestTruthY2)],\n","                               DNN[\"prob\"]: 1} \n","                    predictionTest,yTest,accuracyTest,cTest   = sess.run([DNN[\"output\"], DNN[\"y\"], DNN[\"accuracy\"],DNN[\"cost\"]],\n","                                                                         feed_dict=feed_dict)\n","                    \n","                    epoch_lossTest += cTest\n","                    \n","                    contadorCorrecto = 0\n","                    contadorIncorrecto = 0\n","                   \n","                    for i in range(len(dataTestDeceitY2[x-len(dataTestTruthY2)])):\n","\n","                        if((predictionTest[i][0]>predictionTest[i][1] and yTest[i][0]>yTest[i][1]) or\n","                           (predictionTest[i][0]<predictionTest[i][1] and yTest[i][0]<yTest[i][1])):\n","                          contadorCorrecto = contadorCorrecto + 1\n","\n","                        else:\n","                          contadorIncorrecto = contadorIncorrecto + 1\n","                    if(contadorCorrecto >  contadorIncorrecto):\n","                      accumaccuracy = accumaccuracy + 1\n","                      contadorMentiraPositiva += 1\n","                    contadorTotal = contadorTotal + contadorCorrecto + contadorIncorrecto\n","                    contadorTotalcorrecto = contadorTotalcorrecto + contadorCorrecto\n","                    \n","                #print('Test2: \\t epoch_lossTest2 \\t',epoch_lossTest)\n","                #print('Test2: \\t accuracyPorVideo2 \\t',accumaccuracy/(len(dataTestDeceitY2)+len(dataTestTruthY2)),'\\t accuracyGlobal2 \\t',contadorTotalcorrecto/contadorTotal)\n","                #print('Test2: \\t contadorMentiraPositiva \\t',contadorMentiraPositiva/len(dataTestDeceitY2),'\\t contadorVerdadNegativa \\t',contadorVerdadNegativa/len(dataTestTruthY2))\n","                \n","                \n","                \n","                ########################################################################## impresion tensorboard test2\n","                \n","                tbc.save_value(\"AccuracyTest\", \"accuracyGlobal2\", epoch, contadorTotalcorrecto/contadorTotal)\n","                tbc.flush_line(\"accuracyGlobal2\")\n","                \n","                tbc.save_value(\"LossTest\", \"lossTest2\", epoch, epoch_lossTest)\n","                tbc.save_value(\"AccuracyTest\", \"accuracyPorVideo2\", epoch, accumaccuracy/(len(dataTestTruthY2)+len(dataTestDeceitY2)))\n","                tbc.flush_line(\"lossTest2\")\n","                \n","                roar = contadorTotalcorrecto/contadorTotal\n","                \n","                ########################################################################## condicion para guardar los pesos de la red\n","                \n","                if(roar > 0.60 and roar > bestWeights and acctrain/contador > 0.60):\n","                  saver.save(sess,save_file)\n","                  bestWeights = roar\n","                  print('\\n\\nEpoch', epoch, 'completed out of',hm_epochs)\n","                  print('LossTraining:\\t',epoch_loss,'lossValidation:\\t',epoch_lossVal)\n","                  print('Train: \\t  accuracyValidation:\\t',accuracyVal, '\\t accuracyTraining:\\t',acctrain/contador)\n","                  print('Test2: \\t epoch_lossTest2 \\t',epoch_lossTest)\n","                  print('Test2: \\t accuracyPorVideo2 \\t',accumaccuracy/(len(dataTestDeceitY2)+len(dataTestTruthY2)),'\\t accuracyGlobal2 \\t',contadorTotalcorrecto/contadorTotal)\n","                  print('Test2: \\t contadorMentiraPositiva \\t',contadorMentiraPositiva/len(dataTestDeceitY2),'\\t contadorVerdadNegativa \\t',contadorVerdadNegativa/len(dataTestTruthY2))\n","\n","        tbc.close()\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"G8Rdd_Q3ZUa-","colab_type":"code","outputId":"232316e5-7eb4-4074-925d-c946038491a3","colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["tbc=TensorBoardColab()\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Wait for 8 seconds...\n","TensorBoard link:\n","https://bbb4c63d.ngrok.io\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"scrolled":true,"id":"z9GgiaCote_H","colab_type":"code","colab":{}},"source":["train_neural_network(DNN,hm_epochs = 4000,batch_size=150)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZK-SjQ4FSyBA","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}