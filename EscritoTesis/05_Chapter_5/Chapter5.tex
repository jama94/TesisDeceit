% Chapter 5
%----------------------------------------------------------------------------------------
\chapter{Discusión} % Main chapter title
\label{Chapter5} % For referencing the chapter elsewhere, use \ref{Chapter2} 
\begin{onehalfspacing}
%----------------------------------------------------------------------------------------

A través de la investigación hecha se ha encontrado que existen factores que indican que una persona miente analizando en lenguaje no verbal y varios trabajos han logrado superar al humano en la identificación de mentiras con métodos no invasivos.\\

En la literatura se muestra que el rostro da gran cantidad de información como expresiones, microexpresiones, aumento de temperatura, movimiento ocular, entre otros, que son diferentes en cada persona y que muchos analistas y expertos en mentiras han mostrado que delatan si una persona miente o está diciendo la verdad. Algunos otros expertos han mencionado que ciertos movimientos del rostro, de las manos y en general del lenguaje no verbal también pueden indicar que una persona miente.\\

A través de un video se pueden observar todas éstas características y por esta razón existen varios trabajos que han propuesto diferentes metodologías para detectar mentiras a través de video y han obtenido mejores resultados para detectar mentiras que los especialistas.\\


%%%%%%%


En la literatura se menciona que se ha utilizado el mismo conjunto de datos ocupado en la sección \ref{sec:Modelos_pilotos} y arquitecturas similares ocupadas anteriormente por otros trabajos para detectar acciones humanas y detección de mentiras, pero a pesar de esto, no se reportaba la suficiente información para replicar los experimentos que obtuvieron en la detección de mentiras utilizando como extractor una red neuronal convolucional 3D, causando que se tuvieran que probar gran cantidad de variantes del modelo piloto para intentar lograr resultados similares a ellos lo cuál no se cumplió. Una manera por la cuál podemos lograr los mismos resultados presentados por estos trabajos es combinando las personas del conjunto de entrenamiento y conjunto de prueba. Los datos de Validación que cumplían con estas características y obtenían un resultado similar a los obtenidos por estos trabajos, pero la evaluación no era confiable ya que varios de los individuos contenidos en el Dataset 'Trial' solamente aparecían mintiendo o diciendo verdades, causando que al momento de validar el entrenamiento con los datos de Validación, obtuviera buenos resultados por la memorización de la gente mentirosa y verdadera.\\

Un conjunto de datos ideal para el entrenamiento del modelo propuesto debe contener gran cantidad de personas distintas y cada una de las personas debe tener varios videos en las que se muestra mintiendo y diciendo verdades, esto para evitar que la red tienda a decidir si una persona miente o no por el físico. Estos individuos deben de estar en un escenario tipo interrogatorio en e cuál la persona esta viendo frente a frente a la cámara y ésta se debe de contener estática en todo momento. Cada individuo debe aparecer en cantidades similares de tiempo en los videos de verdad y en los videos de mentira para evitar el desbalance de las clases.\\ 

%Los videos deben de cumplir con los estándares de resolución del mercado (480p,HD,4K).\\

Con los resultados obtenidos en esta investigación se observa que con los diferentes modelos se tienen problemáticas distintas que llevaron a proponer mejoras para combatirlas.
Al inicio el modelo piloto y sus variantes tenían principalmente el problema de sobreajuste, por esta razón se decidió utilizar algunos métodos como la regularización por dropout, balanceo de clases, aumento de extracción de características y  parámetros en la red para combatirlo pero sin éxito. La principal razón de sobreajuste fue la poca cantidad de datos de entrenamiento obtenida del dataset 'Trial' y la aparición de los individuos en una sola clase (verdad o mentira), esto se comprobó al probar las mismas variantes pero con el dataset 'Interview', mostrando un underfitting que indica que los modelos no eran capaz de terminar el proceso de entrenamiento. La principal problemática que tienen los modelos de pocos frames y que causaban underfitting es que los datos de 7,14 y 28 frames a 100x100 píxeles no contenían suficiente información en el tiempo para asegurar que había una declaración completa de una mentira o una verdad y como una misma persona aparecía en múltiples videos de verdad y múltiples videos de mentira, la tarea de clasificación requería de tamaño de red más grande. Las operaciones computacionales propuestas en estos modelos limitaban al poder de cómputo para la extracción de características en las capas convolucionaes 3D, y el aumento de parámetros en las capas completamente conectadas. 
Para solucionar estos problemas se propuso un preprocesamiento en el cuál se redimensionaron las imágenes a 50x50, reduciendo el tamaño de los datos y operaciones a 1/4; también se propuso tener datos con suficiente información para al menos contener un declaración completa de mentira o de verdad. Se probaron varias variantes con este tipo de entrada pero se notó que algunas combinaciones de canales que involucran bordes y agudización de la imagen tales como (GS, KIR, LAP),(GS),(GS, KIR), tendían a causar sobreajuste en el modelo y otras combinaciones que involucraban el flujo óptico (OX, OY) causaban underfitting en en entrenamiento. Las combinación de canales que mejores resultados dieron fueron en las que se involucraban las siluetas de los personajes utilizando los filtros SX y SY, combinados con GS. A pesar de que los modelos con los filtros (GS, SX, SY) tenían mejores resultados, los modelos tendían al sobreajuste si se extraían más números de características en las capas convolucionales o si se aumentaban el número de párametros en la MLP con el objetivo de aumentar la exactitud en las pruenas. Al agregar un dropout fijo a los modelos, causaba underfitting durante el entrenamiento de la red pero al quitar el dropout, en el transcurso de pocas épocas, los modelos se sobre ajustaban a los datos de entrenamiento. Para solucionar esto se implemento una propuesta de dropout variable en la cuál mientras el el accuracy del entrenamiento va incrementando, se va aumentando la probabilidad de desconexión de las neuronas en la MLP. De esta manera el nuevo modelo propuesto incrementaba el accuracy de manera más controlada con el paso de las épocas y evitaba el sobreajuste temprano, de esta manera se obtuvieron mejores resultados en el conjunto de pruebas en las que se encontraban las mismas personas que en el entrenamiento (TestWI:Test Within-person) pero con diferentes declaraciones de mentira y verdad. No se obtuvieron resultados favorables en las pruebas con personas desconocidas (TestPO), lo cuál muestra que la red no es capaz de generalizar el problema de clasificación de mentiras y verdades para todos los individuos.
Esto puede deberse a la hipótesis de expertos en detección de mentiras han descrito, que menciona que a pesar de que hay pistas que delatan mentira o verdad en una persona, no necesariamente delatan mentira o verdad en otra [Vrij et al. 2008].\\




%----------------------------------------------------------------------------------------
\end{onehalfspacing}